name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x]
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build project
      run: npm run build
    
    - name: Run tests
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        TEST_GITHUB_OWNER: jezweb
        TEST_GITHUB_REPO: prompts
      run: npm test
    
    - name: Generate coverage report
      run: npm run test:coverage
    
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.node-version }}
        path: test-results/
        retention-days: 30
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      if: matrix.node-version == '20.x'
      with:
        file: ./coverage/coverage-final.json
        flags: unittests
        name: codecov-umbrella
    
    - name: Comment PR with results
      uses: actions/github-script@v7
      if: github.event_name == 'pull_request' && matrix.node-version == '20.x'
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read test results
          const resultsPath = path.join(process.env.GITHUB_WORKSPACE, 'test-results', 'latest.json');
          const results = JSON.parse(fs.readFileSync(resultsPath, 'utf8'));
          
          // Create comment
          const comment = `## ðŸ§ª Test Results
          
          **Status:** ${results.summary.failed === 0 ? 'âœ… All tests passed!' : 'âŒ Some tests failed'}
          
          | Metric | Value |
          |--------|-------|
          | Total Tests | ${results.summary.total} |
          | Passed | ${results.summary.passed} |
          | Failed | ${results.summary.failed} |
          | Success Rate | ${((results.summary.passed / results.summary.total) * 100).toFixed(1)}% |
          
          ### Performance Summary
          | Tool | Avg Response Time |
          |------|-------------------|
          ${Object.entries(results.performance.statistics)
            .map(([tool, stats]) => `| ${tool} | ${stats.average}ms |`)
            .join('\n')}
          
          [View Full Report](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
    
    - name: Performance regression check
      if: matrix.node-version == '20.x'
      run: |
        node -e "
        const fs = require('fs');
        const results = JSON.parse(fs.readFileSync('./test-results/latest.json', 'utf8'));
        const threshold = 2000; // 2 seconds
        
        let failed = false;
        for (const [tool, stats] of Object.entries(results.performance.statistics)) {
          if (stats.average > threshold) {
            console.error(\`âŒ Performance regression detected for \${tool}: \${stats.average}ms (threshold: \${threshold}ms)\`);
            failed = true;
          }
        }
        
        if (failed) process.exit(1);
        console.log('âœ… All performance checks passed');
        "
    
    - name: Create test badge
      if: github.ref == 'refs/heads/main' && matrix.node-version == '20.x'
      run: |
        # Extract test results
        TOTAL=$(jq '.summary.total' test-results/latest.json)
        PASSED=$(jq '.summary.passed' test-results/latest.json)
        RATE=$(echo "scale=1; $PASSED * 100 / $TOTAL" | bc)
        
        # Determine color
        if [ "${RATE%.*}" -ge 90 ]; then
          COLOR="brightgreen"
        elif [ "${RATE%.*}" -ge 70 ]; then
          COLOR="yellow"
        else
          COLOR="red"
        fi
        
        # Create badge JSON
        echo "{\"schemaVersion\": 1, \"label\": \"tests\", \"message\": \"$PASSED/$TOTAL ($RATE%)\", \"color\": \"$COLOR\"}" > test-badge.json
    
    - name: Deploy test results
      if: github.ref == 'refs/heads/main' && matrix.node-version == '20.x'
      run: |
        # This step would deploy test results to GitHub Pages or similar
        # For now, we just ensure they're available as artifacts
        echo "Test results are available as artifacts"

  benchmark:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'schedule' || github.event_name == 'workflow_dispatch'
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
    
    - name: Install dependencies
      run: npm ci
    
    - name: Build project
      run: npm run build
    
    - name: Run performance benchmark
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # Run extended performance tests
        npm run test:perf || true
        
        # Store benchmark results
        mkdir -p benchmarks
        cp test-results/latest.json benchmarks/benchmark-$(date +%Y%m%d).json
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-results
        path: benchmarks/
        retention-days: 90
    
    - name: Compare with baseline
      run: |
        # This would compare current performance with historical data
        echo "Performance comparison would go here"